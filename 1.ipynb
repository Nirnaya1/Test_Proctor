{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1eea04f-11c0-4eda-8f76-3f72af06e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open camera.\n",
      "Error: Could not read frame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1673.946] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@1673.947] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     19\u001b[0m     exit()\n\u001b[0;32m---> 21\u001b[0m prev_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame1, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Define thresholds for motion detection\u001b[39;00m\n\u001b[1;32m     24\u001b[0m MOUTH_MIN_THRESHOLD \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m  \u001b[38;5;66;03m# Adjust for mouth motion sensitivity\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Could not read frame.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "MOUTH_MIN_THRESHOLD = 0.8 \n",
    "MOUTH_MAX_THRESHOLD = 1\n",
    "FACE_STILL_THRESHOLD = 0.8\n",
    "\n",
    "mou_count=0\n",
    "f_count=0\n",
    "m_count=0\n",
    "f_flag=0\n",
    "m_flag=0\n",
    "mou_flag=0\n",
    "txt_dur=10\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale=1\n",
    "thickness=1\n",
    "color=(0,0,255)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "    gray_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        face_roi_prev = prev_gray[y:y + h, x:x + w]\n",
    "        face_roi_next = gray_frame[y:y + h, x:x + w]\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(face_roi_prev, face_roi_next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        magnitude, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        avg_face_motion = np.mean(magnitude)\n",
    "\n",
    "        face_is_still = avg_face_motion < FACE_STILL_THRESHOLD\n",
    "\n",
    "        if face_is_still:\n",
    "           \n",
    "            mouth_y1 = y + int(2 * h / 3)\n",
    "            mouth_y2 = y + h\n",
    "            mouth_x1 = x\n",
    "            mouth_x2 = x + w\n",
    "\n",
    "           \n",
    "            mouth_roi_prev = prev_gray[mouth_y1:mouth_y2, mouth_x1:mouth_x2]\n",
    "            mouth_roi_next = gray_frame[mouth_y1:mouth_y2, mouth_x1:mouth_x2]\n",
    "\n",
    "           \n",
    "            mouth_flow = cv2.calcOpticalFlowFarneback(mouth_roi_prev, mouth_roi_next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "           \n",
    "            mouth_magnitude, mouth_angle = cv2.cartToPolar(mouth_flow[..., 0], mouth_flow[..., 1])\n",
    "\n",
    "           \n",
    "            avg_mouth_motion = np.mean(mouth_magnitude)\n",
    "            if MOUTH_MIN_THRESHOLD < avg_mouth_motion < MOUTH_MAX_THRESHOLD:\n",
    "                mou_count=mou_count+1\n",
    "                print(m_count)\n",
    "\n",
    "          \n",
    "            hsv = np.zeros((mouth_roi_prev.shape[0], mouth_roi_prev.shape[1], 3), dtype=np.uint8)\n",
    "            hsv[..., 1] = 255\n",
    "            hsv[..., 0] = mouth_angle * 180 / np.pi / 2\n",
    "            hsv[..., 2] = cv2.normalize(mouth_magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "            mouth_flow_visual = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            frame2[mouth_y1:mouth_y2, mouth_x1:mouth_x2] = cv2.addWeighted(\n",
    "                frame2[mouth_y1:mouth_y2, mouth_x1:mouth_x2], 0.5, mouth_flow_visual, 0.5, 0\n",
    "            )\n",
    "    if len(faces)==0:\n",
    "        f_count+=1\n",
    "    if len(faces)>1:\n",
    "        m_count+=1\n",
    "\n",
    "    if f_count>20:\n",
    "        f_flag=txt_dur\n",
    "        f_count=0\n",
    "    if m_count>20:\n",
    "        m_flag=txt_dur\n",
    "        m_count=0\n",
    "    if mou_count>1:\n",
    "        mou_flag=txt_dur\n",
    "        mou_count=0\n",
    "\n",
    "    if f_flag>0:\n",
    "        cv2.putText(frame2,\"No Faces Detected !!!\",(0,30),font,fontscale,color,thickness,cv2.LINE_AA)\n",
    "        f_flag-=1\n",
    "    if m_flag>0:\n",
    "        cv2.putText(frame2,\"Multiple Faces Detected !!!\",(0,60),font,fontscale,color,thickness,cv2.LINE_AA)\n",
    "        m_flag-=1\n",
    "    if mou_flag>0:\n",
    "        cv2.putText(frame2,\"Talking Detected !!!\",(0,90),font,fontscale,color,thickness,cv2.LINE_AA)\n",
    "        mou_flag-=1\n",
    "        \n",
    "\n",
    "    cv2.imshow('Face and Mouth Motion Detection', frame2)\n",
    "\n",
    "\n",
    "    prev_gray = gray_frame\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00addd26-1ed6-45f7-8e21-710e6192b804",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
